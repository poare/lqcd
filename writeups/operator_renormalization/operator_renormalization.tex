\documentclass[11pt, oneside]{article}   	% use "amsart" instead of "article" for AMSLaTeX format
\usepackage[margin = 1in]{geometry}                		% See geometry.pdf to learn the layout options. There are lots.
\geometry{letterpaper}                   		% ... or a4paper or a5paper or ... 
%\geometry{landscape}                		% Activate for rotated page geometry
%\usepackage[parfill]{parskip}    		% Activate to begin paragraphs with an empty line rather than an indent
\usepackage{graphicx}				% Use pdf, png, jpg, or epsÂ§ with pdflatex; use eps in DVI mode
								% TeX will automatically convert eps --> pdf in pdflatex		
\usepackage{amssymb}
\usepackage{amsmath}
\usepackage[shortlabels]{enumitem}
\usepackage{float}
\usepackage{tikz-cd}
\usepackage[compat=1.0.0]{tikz-feynman}   %note you need to compile this in LuaLaTeX for diagrams to render correctly
\usepackage{slashed}
\usepackage{simpler-wick}
\usepackage{subcaption}

\usepackage{amsthm}
\theoremstyle{definition}
\newtheorem{definition}{Definition}[section]
\newtheorem{theorem}{Theorem}[section]
\newtheorem{corollary}{Corollary}[theorem]
\newtheorem{lemma}[theorem]{Lemma}

\newcommand{\N}{\mathbb{N}}
\newcommand{\R}{\mathbb{R}}
\newcommand{\Z}{\mathbb{Z}}
\newcommand{\Q}{\mathbb{Q}}

% make arrow superscripts
\DeclareFontFamily{OMS}{oasy}{\skewchar\font48 }
\DeclareFontShape{OMS}{oasy}{m}{n}{%
         <-5.5> oasy5     <5.5-6.5> oasy6
      <6.5-7.5> oasy7     <7.5-8.5> oasy8
      <8.5-9.5> oasy9     <9.5->  oasy10
      }{}
\DeclareFontShape{OMS}{oasy}{b}{n}{%
       <-6> oabsy5
      <6-8> oabsy7
      <8->  oabsy10
      }{}
\DeclareSymbolFont{oasy}{OMS}{oasy}{m}{n}
\SetSymbolFont{oasy}{bold}{OMS}{oasy}{b}{n}

\DeclareMathSymbol{\smallleftarrow}     {\mathrel}{oasy}{"20}
\DeclareMathSymbol{\smallrightarrow}    {\mathrel}{oasy}{"21}
\DeclareMathSymbol{\smallleftrightarrow}{\mathrel}{oasy}{"24}
%\newcommand{\cev}[1]{\reflectbox{\ensuremath{\vec{\reflectbox{\ensuremath{#1}}}}}}
\newcommand{\vecc}[1]{\overset{\scriptscriptstyle\smallrightarrow}{#1}}
\newcommand{\cev}[1]{\overset{\scriptscriptstyle\smallleftarrow}{#1}}
\newcommand{\cevvec}[1]{\overset{\scriptscriptstyle\smallleftrightarrow}{#1}}

\newcommand{\dbar}{d\hspace*{-0.08em}\bar{}\hspace*{0.1em}}
%SetFonts

\title{Renormalization on the Lattice}
\author{Patrick Oare}
\date{}							% Activate to display a given date or no date

\begin{document}
\maketitle

\section{Regularization-Independent Momentum Subtraction (RI-MOM)}

The RI-MOM scheme (also known as Rome-Southampton) is a renormalization scheme well equipped to deal with 
the lattice, namely because we can calculate the relevant quantities that define the scheme easily on the lattice. The 
lattice spacing $a$ provides us a with a natural UV regulator, and RI-MOM will tell us how to go from such a regulated 
result to a physical observable quantity. 

The RI-MOM has a relatively simple renormalization condition. We will define it here for an arbitrary Green's function, 
for example a three point function. For a renormalization scale $\mu$ and working in a fixed gauge, \textbf{we 
define the amputated, renormalized Green's function at momentum $p^2 = -\mu^2$ to be equal to its tree level 
value}. 

We will denote bare quantities as $a^{(0)}$, and renormalized quantities with a $R$ subscript, when appropriate. 
Note that any quantities computed directly on the lattice are bare, and the entire point of using RI-MOM is to extract 
a sensible definition for these bare quantities. 

In practice on the lattice, there are two things that we must compute. We will work with a specific example here for a 
given quark field $q(x)$. Suppose the operator we are trying to compute is $\mathcal O(z)$. We will renormalize the 
three point function:
\begin{equation}
	G(p) = \frac{1}{V}\sum_{x, y, z}e^{ip\cdot (x - y)}\langle q(x)\mathcal O(z) \overline{q}(y)\rangle~
	\label{eq:green}
\end{equation}
i.e. we are projecting the source and sink to a definite momentum and projecting the operator $\mathcal O(z)$ to zero 
momentum. 

We also will need to compute the momentum projected propagator:
\begin{equation}
	S(p) = \frac{1}{V}\sum_{x, y}e^{ip\cdot(x - y)} S(x, y)~
	\label{eq:mom_prop}
\end{equation}
where $S^{ab}_{ij}(x, y) = \langle q^a_i(x)\bar q^b_j(y)\rangle$ is the standard propagator. On the lattice, the two objects that 
we must compute directly are $S(p)$ and $G(p)$, and everything else follows once we have these quantities. 

To explain the method, our goal is to compute the operator renormalization:
\begin{equation}
	\mathcal O_R(\mu) = \mathcal Z(\mu) \,\mathcal O^{(0)}
\end{equation}
where $\mathcal O_R(\mu)$ is our renormalized operator, $\mathcal Z(\mu)$ is the renormalization coefficient of 
interest, and $\mathcal O^{(0)}$ is the lattice (bare) operator. We will also assume the quark fields have been 
renormalized by some quark field renormalization $\mathcal Z_q$ (note this is the opposite convention studied in 
many QFT classes):
\begin{equation}
	q_R(\mu) = \sqrt{\mathcal Z_q}\,q^{(0)}
\end{equation}
There is an analytical expression for $\mathcal{Z}_q$ on the lattice in the RI-MOM scheme, and it has been determined 
to be:
\begin{equation}
	\mathcal Z_q(p)|_{p^2 = -\mu_R^2} = \left[\frac{tr\left\{-i\sum_{\nu = 1}^4 \gamma_\nu \sin(ap_\nu) a S(p)^{-1}\right\}}{12\sum_{\nu = 1}^4 \sin^2(ap_\nu)}\right]_{p^2 = -\mu^2}
\end{equation}
The twelve on the bottom is a normalization $12 = 3\times 4$ for the number of color and number of spin indices, which we will 
see in many of the expressions. 

Let $\Gamma(p)$ be the \textbf{amputated three point function}, bare or renormalized. We can relate $\Gamma$ to the other 
quantities we have already computed by using the inverse propagator to manually cut the legs off the full three 
point function:
\begin{equation}
	\Gamma(p) = S(p)^{-1} G(p) S(p)^{-1}
\end{equation}
We will denote the tree level version of this by $\Gamma_B$, where the $B$ subscript stands for ``Born". 

Using our quantities already computed on the lattice, we can compute the bare $\Gamma^{(0)}(p)$ directly in terms 
of the renormalized quantities. In the continuum limit, the renormalized Green's function will be:
\begin{align}
	G_R(p; \mu) &= \int d^4x \, d^4 y\, d^4 z\, e^{ip\cdot (x - y)} \langle q_R(x; \mu) \mathcal O_R(z; \mu) \overline 
	q_R(y; \mu) 
	\rangle \\
	&= \mathcal Z_q(\mu) \mathcal Z(\mu) \int d^4x \, d^4 y\, d^4 z\, e^{ip\cdot (x - y)} \langle q^{(0)}(x) \mathcal O^{(0)}
	(z) q^{(0)}(y) \rangle \\
	&= \mathcal Z_q(\mu) \mathcal Z(\mu) G^{(0)}(p)
\end{align}
Similarly, the bare and renormalized propagators are related as:
\begin{equation}
	S_R(p; \mu) = \int d^4x d^4 y\, e^{ip\cdot(x - y)}\langle q_R(x; \mu)\overline q_R(y; \mu)\rangle = \mathcal Z_q(\mu) 
	S^{(0)}(p)
\end{equation}
These relation translates immediately to the amputated Green's function $\Gamma(p)$, as $S^{-1}_R(p; \mu) = \mathcal 
Z_q^{-1}(\mu) (S^{(0)})^{-1}$ we see that:
\begin{equation}
	\Gamma_R(p; \mu) = \mathcal Z_q(\mu)^{-1}\mathcal Z(\mu) \Gamma^{(0)}(p)
\end{equation}

We are now in a position to apply the renormalization condition. We must equate the renormalized, amputated Green's function 
to the tree level Green's function $\Gamma_B(p)$. This gives us:
\begin{equation}
	\mathcal Z_q(\mu)^{-1}\mathcal Z(\mu) \Gamma(p) = \Gamma_B(p)
\end{equation}
Dividing by a conventional factor of 12 as a normalization and inverting, we can clean this expression up into a simple equation 
for $\mathcal Z(\mu)$:
\begin{equation}
	\mathcal Z(p^2 = -\mu^2) = \left[\frac{12\mathcal Z_q(p)}{tr\left\{\Gamma(p)\Gamma_B(p)^{-1}\right\}}\right]_{p^2 
	= -\mu^2}
\end{equation}

\section{Isospin}

We are interested here in computing matrix elements of the operator:
\begin{equation}
	\mathcal O(z) = \mathcal O_u(z) - \mathcal O_d(z)~
	\label{eq:operator_dfn}
\end{equation}
where the quark operators $\mathcal O_q$ are given by
\begin{equation}
	\mathcal O_q(z) = \frac{1}{\sqrt{2}}(\mathcal T^q_{33}(z) - \mathcal T^q_{44}(z))
\end{equation}
and the irreducible tensor operators $\mathcal T^q_{\mu\nu}$ are defined as
\begin{equation}
	\mathcal T^q_{\mu\nu} = \overline q(z)\, \gamma_{\{\mu} \cevvec{D}_{\nu\}}\, q(z)
\end{equation}
with $\cevvec D = \vec D - \cev D$ the symmetrized covariant derivative. Note we define the symmetric and traceless 
component of a tensor to be:
\begin{equation}
	a_{\{\mu}b_{\nu\}} = \frac{1}{2}(a_\mu b_\nu + a_\nu b_\mu) - \frac{1}{4}a_\alpha b^\alpha g_{\mu\nu}
\end{equation} 

We are inserting the operator $\mathcal O_q$ with momentum $\vec p = 0$. We will focus our analysis on the tensor operator 
$\mathcal T^q_{\mu\mu}$ (note there is no sum on $\mu$ here), and note that $\mathcal O(z)$ can be obtained through 
linearity. We may write:
\begin{equation}
	\sum_z\mathcal T^q_{\mu\mu}(z) = \sum_{z, z'}\overline q(z)\, J_\mu(z, z')\,q(z')~
	\label{eq:operator_mom_proj}
\end{equation}
Plugging in the definition of the derivatives:
\begin{align}
	\vec D\psi(z) &= \frac{1}{2}\left(U_\mu(z)\psi(z + \hat\mu) - U_\mu(n - \hat\mu)^\dagger \psi(z - \hat\mu)\right) \\
	\overline\psi(z) \cev D &= \frac{1}{2}\left(\overline\psi(z + \hat\mu)U_\mu(z)^\dagger - 
	\overline\psi(z - \hat\mu) U_\mu(z - \hat\mu)\right)
\end{align}
we find the current $J_\mu(z, z')$ is:
\begin{equation}
	J_\mu(z, z') = \left[U_\mu(z) \delta_{z + \hat\mu, z'} - U_\mu(z')^\dagger\delta_{z - \hat\mu, z'}\right]\gamma_\mu
\end{equation}

We may now use this expansion to compute the three point function for the operator $\mathcal T_\mu = 
\mathcal T^u_{\mu\mu} - \mathcal T^d_{\mu\mu}$ (we can simply take $\mathcal T_3 - \mathcal T_4$ to get the operator of 
interest in Equation~\ref{eq:operator_dfn}). Using Equation~\ref{eq:operator_mom_proj}, we write 
\begin{equation}
	\sum_z \mathcal T_\mu(z) = \sum_{z, z'}\left[\overline u(z)\, J_\mu(z, z')\, u(z') - \overline d(z)\, J_\mu(z, z')\, d(z')\right]
\end{equation}
Plugging this into Equation~\ref{eq:green}, we find that we can expand the total up quark Green's function (here $\alpha, 
\beta$ are Dirac indices) as:
\begin{equation}
	G^{\alpha\beta}(p) = \frac{1}{\sqrt 2}\left(G_3^{\alpha\beta}(p) - G_4^{\alpha\beta} (p)\right)
\end{equation}
where:
\begin{align}
	G_\mu^{\alpha\beta}(p) &= \frac{1}{V}\sum_{x, y, z} e^{-ip(x - y)}\langle u^\alpha(x)\mathcal T_\mu(z) \overline u^\beta(y)
	\rangle \\
	&= \frac{1}{V}\sum_{x, y, z, z'} e^{-ip(x - y)}\left[\langle u^\alpha(x)\overline u^\sigma(z) J_\mu^{\sigma\rho}(z, z') 
	u(z')^\rho\overline u^\beta(y)\rangle - \langle u^\alpha(x)\overline d^\sigma(z) J_\mu^{\sigma\rho}(z, z') d^\rho(z') 
	\overline u^\beta(y)\rangle 
	\right]
\end{align}
Now we perform all possible Wick contractions on the matrix elements to write them as propagators:
\begin{align}
	\langle u^\alpha(x)\overline u^\sigma(z) &J_\mu^{\sigma\rho}(z, z') u^\rho(z')\overline u^\beta(y)\rangle = 
	\langle \wick{
		\c1 u \c1{\overline u} J \c2 u \c2{\overline u}
	} \rangle + \langle \wick{
		\c1 u \c2{\overline u} J \c2 u \c1{\overline u} 
	} \rangle \nonumber \\ 
	&= S^{\alpha\sigma}(x, z) J^{\sigma\rho}_\mu(z, z') S^{\rho\beta}(z', y) + (-1)^3 S^{\alpha\beta}(x, y) 
	J^{\sigma\rho}_\mu(z, z')S^{\rho\sigma}(z', z) \\
	\nonumber\\
	\langle u^\alpha(x)\overline d^\sigma(z) &J_\mu^{\sigma\rho}(z, z') d^\rho(z') \overline u^\beta(y)\rangle = 
	\langle \wick{
		\c1 u \c2{\overline d} J \c2 d \c1{\overline u}
	}\rangle\nonumber \\ 
	&= (-1)^3 S^{\alpha\beta}(x, y) J^{\sigma\rho}_\mu(z, z')S^{\rho\sigma}(z', z)
\end{align}
where the factors of $(-1)$ come from rearranging the contraction so that the contracted pieces are of the form 
$\langle u\overline u\rangle$. The vacuum pieces cancel because the up and down quark propagators are degenerate, so the 
final result is very clean:
\begin{equation}
	G_\mu(p) = \frac{1}{V}\sum_{x, y, z, z'}e^{ip(x - y)} S(x, z) J_\mu (z, z') S(z', y)~
	\label{eq:greens_function}
\end{equation}
This is our central equation, but note that computing this directly on the lattice would involve computing the two point 
propagator $S(x, y)$ at each two points on the lattice. This is much too computationally intensive, so we must resort to 
other techniques to accomplish this. 

There are two primary ways to compute this on the lattice.
We can compute this directly using momentum sources, or 
we can use the sequential source technique. Momentum sources work specifically for Equation~\ref{eq:greens_function}, 
but produce a significantly better signal on a small number of configurations. On the other hand, sequential source 
is much more general, but produces more noise. We will discuss each method below.
%either compute this \textbf{through the operator} or 
%\textbf{through the sink}, and below we will discuss each method and the pros and cons of each. 

\subsection{Momentum sources}

Observe that we can rewrite Equation~\ref{eq:greens_function} as:
\begin{align}
	G_\mu(p) &= \frac{1}{V}\sum_{x, y, z, z'} e^{ipx} S(x, z) J_\mu(z, z') e^{-ipy} S(z', y) \nonumber\\
	&= \frac{1}{V}\sum_{z, z'}\gamma_5\left(\sum_x S(z, x) e^{-ipx}\right)^\dagger\gamma_5 J_\mu(z, z') \left(\sum_y S(z', y) 
	e^{-ipy} \right) \nonumber\\
	&= \frac{1}{V}\sum_{z, z'} \gamma_5 \tilde S_p(z)^\dagger \gamma_5 J_\mu(z, z') \tilde S_p(z')~
	\label{eq:through_sink}
\end{align}
where we have defined $\tilde S_p(z)$ as:
\begin{equation}
	\tilde S_p(z) = \sum_x S(z, x) e^{-ipx}
\end{equation}

The advantage of casting the equation in this form is that we can solve for $\tilde S_p(z)$ directly by inverting the Dirac 
equation with a momentum source, i.e. we have:
\begin{equation}
	\sum_{z} D(x, z) \tilde S_p(z) = e^{-ipx}
\end{equation}
where $D(x, z)$ is the Dirac operator. This means that upon solving for $\tilde S_p(z)$ and plugging this into 
Equation~\ref{eq:through_sink}, we can solve directly for $G_\mu(p)$. 

We can also use the propagator we get from the momentum source inversion to directly compute the propagator 
in Equation~\ref{eq:mom_prop} as follows:
\begin{equation}
	S(p) = \frac{1}{V}\sum_{x, y} e^{ip\cdot (x - y)} S(x, y) = \frac{1}{V}\sum_x e^{ip\cdot x} \tilde S_p(x) 
\end{equation}

This is an exact equation and it does not rely on translational invariance in the infinite statistics limit. 
Therefore, this method will give much better signal and can be run efficiently on a small number of configurations. The 
downside to this is that we require a propagator inversion for each choice of sink momentum. 
To compute $G(p)$ for a large number of sink momenta, as we need to do to extrapolate $\mathcal Z(\mu)$ in the 
continuum limit, a propagator inversion at each sink momenta is not feasible. We must instead choose the sink momentum 
wisely to be able to extract the discretization artifacts and extrapolate $\mathcal Z(\mu)$ to the continuum, which we will 
describe in Section~\ref{sec:artifacts}. 

\subsection{Sequential source method}

In practice we will use the sequential source method, which if implemented correctly does not force us to invert a propagator 
at every sink momenta. This technique is also much more general than the one previously described, but it suffers from 
more noise because it relies on the translational invariance of the lattice, which only exists in the infinite statistics 
limit. The idea of the sequential source method is that if we have an equation involving the full propagator $S(x, y)$, we can 
invert a source which depends on the propagator $S(x)$. For example, in this problem we wish to evaluate 
Equation~\ref{eq:greens_function}, but we cannot simply evaluate $S(x, y)$ for every $x$ and $y$. To get around this, 
consider using a source
\begin{equation}
	b(z) = \sum_{z'} J_\mu(z, z') S(z', 0)~
	\label{eq:source}
\end{equation}
to invert the Dirac equation, which will solve for $M(x)$ in this equation:
\begin{equation}
	\sum_x D(z, x) M(x) = b(z)
\end{equation} 
where $D(x, z)$ is the Dirac operator. Upon inversion, using that $\sum_z S(y, z) D(z, x) = \delta(y - x)$, we can move the 
Dirac operator to the other side as $D^{-1}(y, z) = S(y, z)$ and obtain:
\begin{equation}
	M(x) = \sum_z D^{-1}(x, z) b(z) = \sum_{z, z'} S(x, z) J_\mu(z, z') S(z', 0)~
	\label{eq:inversion}
\end{equation}
Note that we have summed the full propagator $S(x, z)$ for the price of a single inversion of the source $b(z)$. We can then 
reconstruct Equations~\ref{eq:mom_prop} and~\ref{eq:greens_function} for the momentum-projected Green's function 
and propagator in the infinite statistics limit when translational invariance is restored:
\begin{align}
	G_\mu(p)&\rightarrow \frac{1}{V} \sum_x e^{ipx} M(x) = \frac{1}{V} \sum_{x, z, z'} e^{ipx} S(x, z) J_\mu(z, z') S(z', 0) \\
		S(p)&\rightarrow\frac{1}{V}\sum_x e^{ipx} S(x, 0)
\end{align}

To check an implementation of this method, we can invert a sequential propagator which depends on momentum. If we 
replace $S(z', 0)$ in Equation~\ref{eq:source} and invert, we find that:
\begin{align}
	b_\mu^{(p)}(z) &= \sum_{z'} J_\mu(z, z') S_p(z') = \sum_{z', y} e^{-ipy} J_\mu(z, z') S(z', y) \\
	M_\mu^{(p)}(x) &= \sum_{z} S(x, z) b_\mu^{(p)}(z) = \sum_{z, z', y} e^{-ipy} S(x, z) J_\mu(z, z') S(z', y)
\end{align}
When we momentum project to find the Green's function $G(p)$, this no longer relies on translation invariance and should 
match our result with the momentum inversion exactly:
\begin{equation}
	G_\mu(p) = \sum_x e^{ipx} M_\mu^{(p)}(x) = \sum_{x, y, z, z'} e^{ip(x - y)} S(x, z) J_\mu(z, z') S(z', y)
\end{equation}

In our case with a large amount of sink momenta, this method is much more robust than inverting a momentum source 
because we one inversion can give us $G(p)$ at every value of the sink momentum. We will call this construction going 
\textbf{through the operator}, because the inversion in Equation~\ref{eq:inversion} projects the current insertion onto $q = 0$ 
momentum. If we had been interested in projecting the operator onto different momentum values, then we would need to use a 
new sequential source (modify Equation~\ref{eq:source}) for each value of the operator momentum. Pictorially, we are 
inverting at the operator momentum, then tying up at the sink momentum. On the other hand, we reverse the direction of 
inversion and invert our propagator at each sink momentum first, then tie up the line at the operator. This method is called 
going \textbf{through the sink}. We can represent these different methods below, where in our case $q = 0$. 
\begin{figure}[H]
	\centering
	\begin{subfigure}[t]{.48\textwidth}
	\centering
		\feynmandiagram [large, horizontal'=a to c] {
		a [particle = \(p\)] -- [fermion, bend left = 60] b [dot, style = red],
		d -- [boson, momentum = \(q\)] b,
		b -- [fermion, bend left = 60] c  [particle = \(p + q\)],
		a -- [fermion, bend right = 20, opacity = 0] c
                };
            	\caption{Inversion through the operator}
	\end{subfigure}
	~
	\begin{subfigure}[t]{.48\textwidth}
	\centering
		\feynmandiagram [large, horizontal'=a to c] {
		%a [particle = \(p\)] -- [fermion, bend right] c [particle = \(p + q\)],
		%c -- [fermion, bend right] b [empty dot, style = red],
		%d -- [boson, momentum = \(q\)] b
		a [particle = \(p\)] -- [fermion, bend left = 60, opacity = 0] b [dot, style = red],
		d -- [boson, momentum = \(q\)] b,
		b -- [anti fermion, bend left = 60] c  [particle = \(p + q\)],
		a -- [fermion, bend right = 20] c
                };
            	\caption{Inversion through the sink}
	\end{subfigure}
\end{figure}

In this problem inversion through the sink would require too many propagator inversions like in the previous momentum 
source method, and it would also be noisy like inversion through the operator. As such, there is no reason to consider it, 
and I included it here mainly for generality. 

\section{Matching to a continuum scheme}

We must now discuss how to convert between schemes, because typically we want our results to be in a common scheme 
used by many other researchers. For our case, we will convert the renormalization constant $Z_{RI-MOM}(p)$ which we 
have calculated in the previous sections to the $\overline{MS}$ scheme. 

\section{Hypercubic Artifacts}
\label{sec:artifacts}

When we compute observables at a finite lattice spacing $a$, we suffer discretization artifacts which are relics of the explicit 
symmetry breaking $SO(1, 3)\rightarrow H(4)$ suffered by putting the theory on a lattice. Namely, because we have less 
symmetry, there are more invariant quantities of $p^\mu$ in a lattice theory than in the continuum. In the continuum, the 
basic invariant that we can create is $p^2 = p_\mu p^\mu$. 

On the lattice, we can find other invariants because the orbits of $H(4)$ are strictly smaller than the orbits of 
$O(4)$, the Euclidean isometry group in $d = 4$. For example, the vectors $(2, 0, 0, 0)$ and $(1, 1, 1, 1)$ have the same 
value of $p^2 = 4$, yet there is no element $g\in H(4)$ such that $g\cdot (1, 1, 1, 1) = (2, 0, 0, 0)$, i.e. they cannot be 
rotated into one another by hypercubic symmetry. This is because we can define \textit{other hypercubic invariants than 
just $p^2$}. The functions:
\begin{equation}
	p^{[n]} := \sum_\mu p^n
\end{equation}
for $n$ even are also invariants, and these dictate the orbits of momenta under $H(4)$. Since $(1, 1, 1, 1)$ has 
$p^{[4]} = 4$ and $(2, 0, 0, 0)$ has $p^{[4]} = 16$, we can conclude they are distinct momenta under hypercubic 
symmetry and thus cannot live in the same orbit of $H(4)$. 

Any function which is invariant under the action of $H(4)$ must be a function of these hypercubic invariants, much like 
how in the continuum any function which was invariant under Lorentz symmetry was a function of Lorentz scalars like 
$p^2$ or $\slashed p$. Because we are computing out quantities on the lattice which only has $H(4)$ symmetry, these 
extra terms like $p^{[4]}$ can come into play when form factors or renormalization constants are computed, and we must 
take this into account. These are a type of \textbf{discretization artifact} which we will seek to remove when we extrapolate 
to the continuum. 

Another artifact that we must consider when performing calculations on the lattice is that lattice momenta is quantized. 
The possible values that the momenta can take are:
\begin{equation}
	p_\mu = \frac{2\pi}{aL_\mu} n_\mu
\end{equation}
where $n_\mu\in\mathbb Z$ and $L_\mu$ is the size of the lattice in direction $\mu$. 

%We fit according to a general set of hypercubic invariants on the lattice, which in general will have a lot of degrees of freedom to fit reasonably well. So, we use symmetries and other arguments to constrain the functional form of lattice artifacts that we see (i.e. to constrain the $c_i$ coefficients). 

\end{document}